[1mdiff --git a/src/app/talk/page.tsx b/src/app/talk/page.tsx[m
[1mindex aa009c3..ba8493f 100644[m
[1m--- a/src/app/talk/page.tsx[m
[1m+++ b/src/app/talk/page.tsx[m
[36m@@ -39,6 +39,9 @@[m [mexport default function TalkPage() {[m
   const [maxRetries] = useState(3);[m
   const [hasLoggedSession, setHasLoggedSession] = useState(false);[m
   const [lastSpeechTime, setLastSpeechTime] = useState(0);[m
[32m+[m[32m  const [isRecording, setIsRecording] = useState(false);[m
[32m+[m[32m  const [audioRecorder, setAudioRecorder] = useState<MediaRecorder | null>(null);[m
[32m+[m[32m  const [audioChunks, setAudioChunks] = useState<Blob[]>([]);[m
   [m
   const recognitionRef = useRef<SpeechRecognition | null>(null);[m
   const synthRef = useRef<SpeechSynthesis | null>(null);[m
[36m@@ -630,6 +633,12 @@[m [mexport default function TalkPage() {[m
     console.log('turnMicOn called - enabling microphone');[m
     setMicEnabled(true);[m
     await initializeAudioAnalysis();[m
[32m+[m[41m    [m
[32m+[m[32m    // Start audio recording when first turning on mic (if not already recording)[m
[32m+[m[32m    if (!isRecording) {[m
[32m+[m[32m      await startAudioRecording();[m
[32m+[m[32m    }[m
[32m+[m[41m    [m
     if (recognitionRef.current) {[m
       try {[m
         recognitionRef.current.start();[m
[36m@@ -705,9 +714,72 @@[m [mexport default function TalkPage() {[m
     return `${mins}:${secs.toString().padStart(2, '0')}`;[m
   };[m
 [m
[32m+[m[32m  const startAudioRecording = async () => {[m
[32m+[m[32m    try {[m
[32m+[m[32m      console.log('Attempting to start audio recording...');[m
[32m+[m[32m      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });[m
[32m+[m[32m      const recorder = new MediaRecorder(stream);[m
[32m+[m[41m      [m
[32m+[m[32m      recorder.ondataavailable = (event) => {[m
[32m+[m[32m        console.log('Audio data available, size:', event.data.size);[m
[32m+[m[32m        if (event.data.size > 0) {[m
[32m+[m[32m          setAudioChunks(prev => {[m
[32m+[m[32m            const newChunks = [...prev, event.data];[m
[32m+[m[32m            console.log('Total audio chunks:', newChunks.length);[m
[32m+[m[32m            return newChunks;[m
[32m+[m[32m          });[m
[32m+[m[32m        }[m
[32m+[m[32m      };[m
[32m+[m[41m      [m
[32m+[m[32m      recorder.onstart = () => {[m
[32m+[m[32m        console.log('MediaRecorder started');[m
[32m+[m[32m      };[m
[32m+[m[41m      [m
[32m+[m[32m      recorder.onstop = () => {[m
[32m+[m[32m        console.log('MediaRecorder stopped');[m
[32m+[m[32m      };[m
[32m+[m[41m      [m
[32m+[m[32m      recorder.start(1000); // Record in 1-second chunks[m
[32m+[m[32m      setAudioRecorder(recorder);[m
[32m+[m[32m      setIsRecording(true);[m
[32m+[m[32m      console.log('Audio recording started successfully');[m
[32m+[m[32m    } catch (error) {[m
[32m+[m[32m      console.error('Error starting audio recording:', error);[m
[32m+[m[32m      setError('Could not start audio recording');[m
[32m+[m[32m    }[m
[32m+[m[32m  };[m
[32m+[m
[32m+[m[32m  const stopAudioRecording = (): Promise<void> => {[m
[32m+[m[32m    return new Promise((resolve) => {[m
[32m+[m[32m      if (audioRecorder && audioRecorder.state !== 'inactive') {[m
[32m+[m[32m        console.log('Stopping audio recording...');[m
[32m+[m[41m        [m
[32m+[m[32m        audioRecorder.onstop = () => {[m
[32m+[m[32m          console.log('Audio recording stopped, total chunks:', audioChunks.length);[m
[32m+[m[32m          audioRecorder.stream.getTracks().forEach(track => track.stop());[m
[32m+[m[32m          setIsRecording(false);[m
[32m+[m[32m          resolve();[m
[32m+[m[32m        };[m
[32m+[m[41m        [m
[32m+[m[32m        audioRecorder.stop();[m
[32m+[m[32m      } else {[m
[32m+[m[32m        setIsRecording(false);[m
[32m+[m[32m        resolve();[m
[32m+[m[32m      }[m
[32m+[m[32m    });[m
[32m+[m[32m  };[m
[32m+[m
[32m+[m[32m  const getAudioBlob = (): Blob | null => {[m
[32m+[m[32m    if (audioChunks.length > 0) {[m
[32m+[m[32m      return new Blob(audioChunks, { type: 'audio/webm' });[m
[32m+[m[32m    }[m
[32m+[m[32m    return null;[m
[32m+[m[32m  };[m
[32m+[m
   const logChatSession = async () => {[m
     if (hasLoggedSession || !activeProfile || messages.length === 0 || !user) {[m
[31m-      return;[m
[32m+[m[32m      console.log('Early return from logChatSession:', { hasLoggedSession, activeProfile: !!activeProfile, messageCount: messages.length });[m
[32m+[m[32m      return { success: false };[m
     }[m
 [m
     try {[m
[36m@@ -731,35 +803,38 @@[m [mexport default function TalkPage() {[m
       if (response.ok) {[m
         const data = await response.json();[m
         console.log('Chat session logged successfully:', data);[m
[31m-        setSuccessMessage('Chat session saved successfully!');[m
[31m-        setTimeout(() => setSuccessMessage(null), 3000); // Auto-dismiss after 3 seconds[m
[31m-        return true; // Return success status[m
[32m+[m[32m        return { success: true, caseId: data.id }; // Return success status with case ID[m
       } else {[m
[31m-        const errorData = await response.json();[m
[31m-        console.error('Failed to log chat session:', errorData);[m
[31m-        setError(`Failed to save chat session: ${errorData.error || 'Unknown error'}`);[m
[31m-        return false;[m
[32m+[m[32m        console.error('Failed to log chat session');[m
[32m+[m[32m        return { success: false };[m
       }[m
     } catch (error) {[m
       console.error('Error logging chat session:', error);[m
[31m-      setError(`Failed to save chat session: ${error instanceof Error ? error.message : 'Network error'}`);[m
[31m-      return false;[m
[32m+[m[32m      return { success: false };[m
     }[m
   };[m
 [m
   const endCall = async () => {[m
[31m-    console.log('Ending call - starting cleanup');[m
[32m+[m[32m    // Show loading state[m
[32m+[m[32m    setIsProcessing(true);[m
[32m+[m[32m    setError("Ending session and generating feedback...");[m
     [m
[31m-    // Immediately stop all speech synthesis[m
[31m-    stopAllSpeech();[m
[32m+[m[32m    // Prevent beforeunload handler from interfering[m
[32m+[m[32m    setHasLoggedSession(true);[m
     [m
[31m-    // Stop speech recognition immediately[m
[32m+[m[32m    // Stop all audio/speech immediately and clean up handlers[m
     if (recognitionRef.current) {[m
[31m-      console.log('Stopping speech recognition');[m
[32m+[m[32m      recognitionRef.current.onresult = null;[m
[32m+[m[32m      recognitionRef.current.onerror = null;[m
[32m+[m[32m      recognitionRef.current.onend = null;[m
       recognitionRef.current.stop();[m
     }[m
[31m-    [m
[31m-    // Stop timer immediately[m
[32m+[m[32m    if (synthRef.current) {[m
[32m+[m[32m      synthRef.current.cancel();[m
[32m+[m[32m    }[m
[32m+[m[32m    if (window.speechSynthesis) {[m
[32m+[m[32m      window.speechSynthesis.cancel(); // Additional stop for speech synthesis[m
[32m+[m[32m    }[m
     if (timerRef.current) {[m
       console.log('Clearing timer');[m
       clearInterval(timerRef.current);[m
[36m@@ -769,22 +844,9 @@[m [mexport default function TalkPage() {[m
     // Stop audio analysis immediately (this now includes microphone stream cleanup)[m
     console.log('Stopping audio analysis and microphone stream');[m
     stopAudioAnalysis();[m
[31m-    [m
[31m-    // Stop user video stream if active[m
[31m-    if (userVideoStream) {[m
[31m-      console.log('Stopping user video stream');[m
[31m-      userVideoStream.getTracks().forEach(track => {[m
[31m-        track.stop();[m
[31m-        console.log('Video track stopped');[m
[31m-      });[m
[31m-      setUserVideoStream(null);[m
[31m-    }[m
[31m-    [m
[31m-    // Reset al